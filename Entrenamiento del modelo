import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import kagglehub
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

path = kagglehub.dataset_download("hasibalmuzdadid/global-air-pollution-dataset")
print("Path to dataset files:", path)

import os


path = "/root/.cache/kagglehub/datasets/hasibalmuzdadid/global-air-pollution-dataset/versions/2"


print(os.listdir(path))

data = pd.read_csv(f"{path}/global air pollution dataset.csv")



data = data.dropna()


data = data.select_dtypes(include=[np.number])


correlation_matrix = data.corr()


sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.show()



correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.show()




correlation_threshold = 0.3
relevant_features = correlation_matrix['PM2.5 AQI Value'][abs(correlation_matrix['PM2.5 AQI Value']) > correlation_threshold].index.tolist()

data_filtered = data[relevant_features]


X = data_filtered.drop(columns=['PM2.5 AQI Value'])
y = data_filtered['PM2.5 AQI Value']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)


y_pred = model.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
print(f'Error cuadr√°tico medio: {mse}')
